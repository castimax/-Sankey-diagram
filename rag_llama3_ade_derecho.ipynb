{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRHc+/t2wDTkBqRRhkaPJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castimax/-Sankey-diagram/blob/master/rag_llama3_ade_derecho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t64-tgzJdALJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install langchain==0.0.184\n",
        "!pip install pypdf==3.8.1\n",
        "!pip install chromadb==0.3.21\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!pip install huggingface_hub==0.14.1\n",
        "!pip install gradio==3.23.0\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "from google.colab import drive\n",
        "from langchain import PromptTemplate\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFaceHub\n",
        "import gdown\n",
        "\n",
        "# Configuración de la API de HuggingFace\n",
        "HUGGINGFACE_API_KEY = \"tu_clave_api_de_huggingface\"  # Reemplaza esto con tu clave real\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACE_API_KEY"
      ],
      "metadata": {
        "id": "O7Z-sRGzeTnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG con Llama3 70B para Exámenes de ADE y Derecho en Google Colab\n",
        "\n",
        "Este proyecto implementa un sistema de Generación Aumentada por Recuperación (RAG) utilizando el modelo Llama3 70B a través de HuggingFace Hub en Google Colab. Está diseñado para responder preguntas de examen en el contexto del doble grado de ADE y Derecho, simulando las respuestas de un catedrático experto y exigente.\n",
        "\n",
        "## Instrucciones de uso\n",
        "\n",
        "1. Preparación en Google Drive:\n",
        "   - Crea una carpeta llamada \"ADE_Derecho_PDFs\" en tu Google Drive.\n",
        "   - Sube tus archivos PDF de ADE y Derecho a esta carpeta.\n",
        "\n",
        "2. Configuración en Google Colab:\n",
        "   - Abre Google Colab (https://colab.research.google.com/).\n",
        "   - Crea un nuevo notebook o abre uno existente.\n",
        "   - Copia y pega el contenido del archivo `rag_llama3_ade_derecho.ipynb` en las celdas del notebook.\n",
        "\n",
        "3. Configuración de la API de HuggingFace:\n",
        "   - En la celda donde se define `HUGGINGFACE_API_KEY`, reemplaza \"tu_clave_api_de_huggingface\" con tu clave API real de HuggingFace.\n",
        "\n",
        "4. Ejecución del notebook:\n",
        "   - Ejecuta todas las celdas en orden.\n",
        "   - Cuando se te solicite, autoriza a Colab para acceder a tu Google Drive.\n",
        "\n",
        "5. Uso de la interfaz:\n",
        "   - Después de ejecutar todas las celdas, se generará un enlace público a la interfaz Gradio.\n",
        "   - Abre ese enlace en tu navegador.\n",
        "   - Escribe tu pregunta en el cuadro de texto.\n",
        "   - Ajusta el número máximo de páginas para la respuesta con el control deslizante.\n",
        "   - Haz clic en \"Submit\" para obtener la respuesta del catedrático virtual.\n",
        "\n",
        "## Notas importantes\n",
        "\n",
        "- Asegúrate de tener suficiente espacio en tu Google Drive para los archivos PDF y la base de conocimientos generada.\n",
        "- El proceso de carga y procesamiento de PDFs puede llevar tiempo dependiendo del número y tamaño de los archivos.\n",
        "- La interfaz Gradio estará disponible públicamente mientras tu sesión de Colab esté activa.\n",
        "\n",
        "## Requisitos\n",
        "\n",
        "- Cuenta de Google (para acceder a Google Colab y Google Drive)\n",
        "- Clave API de HuggingFace\n",
        "\n",
        "## Licencia\n",
        "\n",
        "[MIT](https://choosealicense.com/licenses/mit/)"
      ],
      "metadata": {
        "id": "DgkYnx9IdK9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Celda de configuración para RAG\n",
        "\n",
        "import os\n",
        "\n",
        "# Configurar la API key de HuggingFace\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "# Configurar la ruta del directorio PDF (si es necesario)\n",
        "os.environ[\"PDF_DIRECTORY_PATH\"] = \"./data\"\n",
        "\n",
        "# Verificar que las variables se han cargado correctamente\n",
        "print(\"Variables de entorno cargadas:\")\n",
        "print(f\"HUGGINGFACE_API_TOKEN: {os.getenv('HUGGINGFACEHUB_API_TOKEN')[:10]}...\")  # Mostramos solo los primeros 10 caracteres por seguridad\n",
        "print(f\"PDF_DIRECTORY_PATH: {os.getenv('PDF_DIRECTORY_PATH')}\")\n",
        "\n",
        "# Importaciones necesarias para el RAG\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Configurar el modelo Meta-Llama-3-70B\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-70B\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_length\": 512,\n",
        "        \"max_new_tokens\": 512,\n",
        "    },\n",
        "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        ")\n",
        "\n",
        "print(\"Modelo configurado correctamente.\")"
      ],
      "metadata": {
        "id": "JuVkiWKWkc5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# URL del archivo compartido\n",
        "shared_file_url = \"https://drive.google.com/file/d/1eKDp0tQvYPjEC86O4mVerHd0v-67tCw-/view?usp=drivesdk\"\n",
        "\n",
        "# Extraer el ID del archivo de la URL\n",
        "file_id = shared_file_url.split('/')[-2]\n",
        "\n",
        "# Descargar el archivo\n",
        "output = '/content/temas_ade_derecho.pdf'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n",
        "\n",
        "# Cargar el documento PDF\n",
        "documents = []\n",
        "loader = PyPDFLoader(output)\n",
        "documents.extend(loader.load())\n",
        "\n",
        "print(f\"Se han cargado {len(documents)} páginas del documento.\")"
      ],
      "metadata": {
        "id": "wJ6TILNEgsbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dividir documentos en chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Crear embeddings y base de datos vectorial\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "modPCKAXgzoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configurar el modelo Meta-Llama-3-70B\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-70B\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_length\": 512,\n",
        "        \"max_new_tokens\": 512,\n",
        "    },\n",
        "    huggingfacehub_api_token=HUGGINGFACE_API_KEY\n",
        ")\n",
        "\n",
        "# Crear plantilla de prompt\n",
        "template = \"\"\"Asume el rol de un catedrático experto y muy exigente del doble grado de ADE y Derecho. Estás evaluando exámenes y respondiendo preguntas técnicas. Utiliza un lenguaje técnico y preciso, citando los preceptos legales pertinentes según la legislación jurídica vigente española. Responde en prosa, aunque puedes usar bullet points cuando sea apropiado para mejorar la claridad.\n",
        "\n",
        "Contexto del examen: {context}\n",
        "\n",
        "Pregunta del examen: {question}\n",
        "\n",
        "Longitud máxima de respuesta: {max_words} palabras\n",
        "\n",
        "Respuesta del catedrático:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"context\", \"question\", \"max_words\"]\n",
        ")\n",
        "\n",
        "# Crear la cadena de recuperación y generación\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt}\n",
        ")"
      ],
      "metadata": {
        "id": "17pNvYpig3YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lanzar la interfaz\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "YittLddQg_WF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}